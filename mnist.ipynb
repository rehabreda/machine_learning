{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/rehabreda/machine_learning/blob/master/mnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "u_YyACePXagR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NV-A5DSMXlXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "94165d6b-db43-4837-94e5-abb7930acc9c"
      },
      "cell_type": "code",
      "source": [
        "mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-5346a1ecf119>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PQwinkvaYOWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_nodes_hl1=500\n",
        "n_nodes_hl2=500\n",
        "n_nodes_hl3=500\n",
        "n_classes=10\n",
        "batch_size=100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsTIs_2BYklk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=tf.placeholder('float',[None,784])\n",
        "y=tf.placeholder('float')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49YQo_eBYyJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def neural_network_model(data):\n",
        "  hidden_layer1={'weights':tf.Variable(tf.random_normal([784,n_nodes_hl1])),\n",
        "                  'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "  hidden_layer2={'weights':tf.Variable(tf.random_normal([n_nodes_hl1,n_nodes_hl2])),\n",
        "                  'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "  hidden_layer3={'weights':tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])),\n",
        "                  'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
        "  output_layer={'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])),\n",
        "                  'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "  \n",
        "  l1=tf.add(tf.matmul(data,hidden_layer1['weights']),hidden_layer1['biases'])\n",
        "  l1=tf.nn.relu(l1)\n",
        "  \n",
        "  l2=tf.add(tf.matmul(l1,hidden_layer2['weights']),hidden_layer2['biases'])\n",
        "  l2=tf.nn.relu(l2)\n",
        "  \n",
        "  l3=tf.add(tf.matmul(l2,hidden_layer3['weights']),hidden_layer3['biases'])\n",
        "  l3=tf.nn.relu(l3)\n",
        "  \n",
        "  output=tf.add(tf.matmul(l3,output_layer['weights']),output_layer['biases'])\n",
        "  \n",
        "  return output\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3IAez0wa5zV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_neural_network(x):\n",
        "  prediction=neural_network_model(x)\n",
        "  cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
        "  optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
        "  n_epochs=10\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for epoch in range(n_epochs):\n",
        "      epoch_loss=0\n",
        "      for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "        epoch_x,epoch_y=mnist.train.next_batch(batch_size)\n",
        "        _,c=sess.run([optimizer,cost],feed_dict={x:epoch_x,y:epoch_y})\n",
        "        epoch_loss+=c\n",
        "        \n",
        "      print('epoch',epoch,'with loss :',epoch_loss)\n",
        "      \n",
        "    correct=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "    accuracy=tf.reduce_mean(tf.cast(correct,'float'))\n",
        "    print('Accuracy:',accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eoKiDoUpfzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c4f1c9cc-9277-4e5a-8682-b97a0fd799eb"
      },
      "cell_type": "code",
      "source": [
        "train_neural_network(x)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 with loss : 1649892.5457763672\n",
            "epoch 1 with loss : 404512.24723911285\n",
            "epoch 2 with loss : 222343.51897177845\n",
            "epoch 3 with loss : 132437.1061590314\n",
            "epoch 4 with loss : 79101.89616576806\n",
            "epoch 5 with loss : 54527.61308257818\n",
            "epoch 6 with loss : 37592.88252997726\n",
            "epoch 7 with loss : 26010.192771435977\n",
            "epoch 8 with loss : 24562.581153295934\n",
            "epoch 9 with loss : 18951.80940394223\n",
            "Accuracy: 0.9484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W0Bu0lvsphVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}